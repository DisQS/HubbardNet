{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434bb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#from matplotlib import rc\n",
    "import numpy as np\n",
    "\n",
    "from one_d_excited_states import *\n",
    "import matrix_element as me\n",
    "\n",
    "from os import path\n",
    "import os\n",
    "from copy import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "\n",
    "# Check to see if gpu is available. If it is, use it else use the cpu\n",
    "if torch.cuda.is_available() and use_gpu:\n",
    "    device = torch.device('cuda')\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print('Using GPU.')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "    if not torch.cuda.is_available() and use_gpu: \n",
    "        use_gpu = False \n",
    "        print('GPU not available. Using CPU.')\n",
    "    else: \n",
    "        print('Using CPU.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_list = [7]\n",
    "N = N_list[0]\n",
    "model_list = []\n",
    "\n",
    "M = 7\n",
    "w = M\n",
    "h = int(M/w)\n",
    "pbc = False\n",
    "\n",
    "for (n_idx, N) in enumerate(N_list): \n",
    "    O = N\n",
    "    \n",
    "    model = me.Bose_Hubbard(N, O, w=w, h=h, M=M, pbc=pbc)\n",
    "    model_list.append(model)\n",
    "    \n",
    "print(\"The size of the Hamiltonian is {}\".format(model.tot_states))\n",
    "\n",
    "t = 1 \n",
    "U_max = 5\n",
    "V = 0\n",
    "U_list_all = np.arange(1, U_max+1, .25)\n",
    "#U_list_all =np.array([4])\n",
    "mu_list_all = np.linspace(0, 10, 5)\n",
    "mu_list_all = np.array([0.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c0c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "## NN\n",
    "\n",
    "S = 50 # number of sample of the MH sampler (not used)\n",
    "init = 1 # the first state to sample in Metropolis Hastings (has nothing to do with the optimizer!) (not used)\n",
    "\n",
    "# Network parameters\n",
    "D_hid = 400 # the number ofneurons in the hidden layer\n",
    "lr = 5e-6 # learning rate \n",
    "#lr = 5e-6 # learning rate \n",
    "#lr = 1e-8 # learning rate\n",
    "#epochs = 10000\n",
    "epochs = 1000\n",
    "loss_diff = 1e-7\n",
    "grad_cut = 1e-6\n",
    "check_point = 100 # print out the energy every X points\n",
    "use_sampler = False # for now, only support ground state (not working anyway)\n",
    "\n",
    "# Model parameters\n",
    "U_train = np.ones(3)*2\n",
    "t_train = 1.\n",
    "\n",
    "U_train = np.logspace(-2, 2, 9, endpoint = True)\n",
    "\n",
    "mu_train = np.zeros_like(U_train)\n",
    "c1=0\n",
    "c2=0\n",
    "c3=1\n",
    "qlist=[1, 2, 1000000.0,-1,-2]\n",
    "#qlist=[-1]\n",
    "\n",
    "n_avg_states=50\n",
    "target_epsilon=0.5\n",
    "\n",
    "min_state = 0\n",
    "max_state = 1\n",
    "\n",
    "n_excited = max_state - 1\n",
    "\n",
    "# paths to save and load weights \n",
    "#fpath ='/storage/disqs/phrczh/HubbardNet/weights/'\n",
    "\n",
    "#t0 = time.time()\n",
    "\n",
    "loss_all = [] \n",
    "penalty_all = []\n",
    "nn = []\n",
    "energy_all = []\n",
    "overlap_all = []\n",
    "frac_dim_all0 = []\n",
    "frac_dim_all1 = []\n",
    "frac_dim_all2 = []\n",
    "frac_dim_all3 = []\n",
    "frac_dim_all4 = []\n",
    "#frac_dim_all5 = []\n",
    "\n",
    "\n",
    "\n",
    "# filepath for excited states\n",
    "fname = \"./weights/ep-1000-ADAM-weights_M{}N{}_V{}_Umax{}_Umin{}_L5_D{}-avgexcited_lr{}_len_Utrain{}_c1{}c2{}c3{}qlist{}n_avg_states{}target_epsilon{}\".format(M,N,V,np.max(U_train),np.min(U_train),D_hid,lr,len(U_train),c1,c2,c3,qlist,n_avg_states,target_epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "def call_NN(lr, n_excited):\n",
    "    if n_excited: \n",
    "        if n_excited == 1 :\n",
    "            load_states_indv = [0]\n",
    "        else:\n",
    "            load_states_indv = range(1, n_excited)\n",
    "        gs_flag = False\n",
    "        es_flag = True\n",
    "\n",
    "    else: # ground states\n",
    "        load_states_indv = [0]\n",
    "        gs_flag = True\n",
    "        es_flag = False\n",
    "    \n",
    "    load_states = np.max(load_states_indv)  # total number of states being fixed \n",
    "  \n",
    "    params = {'D_hid': D_hid, \n",
    "              'step_size': lr, \n",
    "              'max_iteration':epochs,\n",
    "              'check_point': check_point,\n",
    "              'loss_diff': loss_diff, \n",
    "              'steps': 1000, # reset learning every N steps\n",
    "              'loss_check_steps': 50, # check the local every N steps\n",
    "              'grad_cut': grad_cut,  # stopping condition in the total gradient \n",
    "              'weight_init': False, \n",
    "              'zero_bias': False, \n",
    "              'gs_epochs': 1000, # the maximum number of steps to minimize the ground state\n",
    "              'gs_flag': gs_flag, # ground state only\n",
    "              'es_flag': es_flag,  # excited state only\n",
    "              'regularization': True, \n",
    "              'load_states': load_states, # the number of states loaded \n",
    "              'load_states_indv': load_states_indv, \n",
    "              'rand_steps': 5000, \n",
    "              'load_weights_from_previous_state': False, # randomize the projection every N steps\n",
    "              'use_gpu': use_gpu, \n",
    "              'weight_decay': 0,\n",
    "              'perturb_amp': 0.00, \n",
    "              'dropout': 0.0}\n",
    "  \n",
    "    print(\"Begin optimizing for state {}\".format(n_excited))\n",
    "\n",
    "    #fc1, Loss_history, dot_history, all_E_list = train_NN(model_list, N_list, mu_train, U_train, t_train, V, S, params, fname, \\\n",
    "                                            #use_sampler=use_sampler, init=init, loadweights=False,\\\n",
    "                                            #fname_load=fname, n_excited=n_excited)\n",
    "    fc1, Loss_history, energy_history, overlap_history, frac_dim_history0, frac_dim_history1, frac_dim_history2, frac_dim_history3, frac_dim_history4, dot_history, all_E_list = train_NN(model_list, N_list, mu_train, U_train, t_train, c1, c2, c3, qlist, V, S, params, fname, \\\n",
    "                                            use_sampler=use_sampler, init=init, loadweights=False,\\\n",
    "                                            fname_load=fname, n_excited=n_excited)\n",
    "\n",
    "    #return fc1, Loss_history, dot_history\n",
    "    return fc1, Loss_history, energy_history, overlap_history, frac_dim_history0, frac_dim_history1, frac_dim_history2, frac_dim_history3, frac_dim_history4, dot_history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for n_excited in range(min_state, max_state):\n",
    "    \n",
    "    fc1, Loss_history, energy_history, overlap_history, frac_dim_history0, frac_dim_history1, frac_dim_history2, frac_dim_history3, frac_dim_history4, dot_history = call_NN(lr, n_excited)\n",
    "\n",
    "    nn.append(fc1)\n",
    "    loss_all.append(Loss_history)\n",
    "    energy_all.append(energy_history)\n",
    "    overlap_all.append(overlap_history)\n",
    "    penalty_all.append(dot_history)\n",
    "    frac_dim_all0.append(frac_dim_history0)\n",
    "    frac_dim_all1.append(frac_dim_history1)\n",
    "    frac_dim_all2.append(frac_dim_history2)\n",
    "    frac_dim_all3.append(frac_dim_history3)\n",
    "    frac_dim_all4.append(frac_dim_history4)\n",
    "    #frac_dim_all5.append(frac_dim_history5)\n",
    "    \n",
    "tf = time.time()\n",
    "print(\"Training time = {} seconds.\".format(tf-t0))\n",
    "#np.savetxt(f'./time/M-{M}-N-{N}-U_train-{U_train}-lr-{lr}-num_th-{torch.get_num_threads()}-interop-{torch.get_num_interop_threads()}-use_gpu-{use_gpu}-adam.csv',[tf-t0])\n",
    "np.savetxt(f'./time-excited-target/epoch-{epochs}-ADAM-excited-c1-{c1}-c2-{c2}-c3-{c3}-qlist-{qlist}-epsilon-{target_epsilon}-n_avg_states-{n_avg_states}-M-{M}-N-{N}-len_U_train-{len(U_train)}-lr-{lr}-num_th-{torch.get_num_threads()}-interop-{torch.get_num_interop_threads()}-use_gpu-{use_gpu}.csv',[tf-t0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19617338",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_test = np.logspace(-2.125, 2.125, 69, endpoint = True) \n",
    "#U_test = np.logspace(-2, 2, 121, endpoint = True) \n",
    "#U_test = np.logspace(-3, 2, 121, endpoint = True) \n",
    "#U_test =np.array([4])\n",
    "mu_test = np.zeros_like(U_test)\n",
    "\n",
    "fc1 = load_weights(fname + \"gs\", M, D_hid)\n",
    "E_train, wf_gs = wf_e_calc(model_list[0], N_list[0], U_train, mu_train, t, V, 0, 0, fc1, use_gpu=True)\n",
    "E_test, wf_gs_test = wf_e_calc(model_list[0], N_list[0], U_test, mu_test, t, V, 0, 0, fc1, use_gpu=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
